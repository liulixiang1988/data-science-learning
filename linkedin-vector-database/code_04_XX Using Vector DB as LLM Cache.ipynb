{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e5dcda",
   "metadata": {},
   "source": [
    "## 04.03 Setting up the Milvus Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "492aa787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating database : cache_db\n"
     ]
    }
   ],
   "source": [
    "#Setup database & collection\n",
    "from pymilvus import connections\n",
    "from pymilvus import db,Collection\n",
    "\n",
    "from pymilvus import utility\n",
    "\n",
    "#Names for connections, database and collections\n",
    "conn_name = \"cache_conn\"\n",
    "db_name=\"cache_db\"\n",
    "collection_name=\"llm_cache\"\n",
    "\n",
    "#Create a connection to Milvus\n",
    "connections.add_connection(\n",
    "    cache_conn={\n",
    "        \"host\": \"localhost\",\n",
    "        \"port\": \"19530\",\n",
    "        \"username\" : \"username\",\n",
    "        \"password\" : \"password\"\n",
    "    })\n",
    "\n",
    "\n",
    "#Connect\n",
    "connections.connect(conn_name)\n",
    "\n",
    "#Create a DB if not already present\n",
    "current_dbs=db.list_database(using=conn_name)\n",
    "\n",
    "if ( db_name not in current_dbs):\n",
    "    print(\"Creating database :\", db_name)\n",
    "    resume_db = db.create_database(db_name, using=conn_name) #default db is \"default\"\n",
    "else:\n",
    "    print(db_name, \": Database already exists\")\n",
    "\n",
    "#Switch to the new database\n",
    "db.using_database(db_name, using=conn_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1aece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema :  {'auto_id': True, 'description': 'Cache for LLM', 'fields': [{'name': 'cache_id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'prompt_text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 2048}}, {'name': 'response_text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 2048}}, {'name': 'prompt_embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 1536}}], 'enable_dynamic_field': True} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create a Collection for cache\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection\n",
    "import json\n",
    "\n",
    "#Define fields in the cache\n",
    "#Autogenerated ID field for each entity\n",
    "cache_id = FieldSchema(\n",
    "    name=\"cache_id\",\n",
    "    dtype=DataType.INT64,\n",
    "    auto_id=True,\n",
    "    is_primary=True,\n",
    "    max_length=32)\n",
    "\n",
    "#Text for the input prompt\n",
    "prompt_text= FieldSchema(\n",
    "    name=\"prompt_text\",\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=2048)\n",
    "\n",
    "#Text for the LLM response\n",
    "response_text= FieldSchema(\n",
    "    name=\"response_text\",\n",
    "    dtype=DataType.VARCHAR,\n",
    "    max_length=2048)\n",
    "\n",
    "#Embedding for the input prompt\n",
    "prompt_embedding = FieldSchema(\n",
    "    name=\"prompt_embedding\",\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=1536 #Define based on embedding used\n",
    ")\n",
    "\n",
    "#Define the schema for the cache collection\n",
    "cache_schema=CollectionSchema(\n",
    "    fields=[cache_id, prompt_text, response_text, prompt_embedding],\n",
    "    description=\"Cache for LLM\",\n",
    "    enable_dynamic_field=True\n",
    ")\n",
    "\n",
    "#Create the collection\n",
    "cache_collection=Collection(\n",
    "    name=collection_name,\n",
    "    schema=cache_schema,\n",
    "    using=conn_name,\n",
    "    shard_num=2\n",
    ")\n",
    "\n",
    "print(\"Schema : \", cache_collection.schema, \"\\n\")\n",
    "\n",
    "#Build an index for the prompt embedding field\n",
    "index_params = {\n",
    "    \"metric_type\":\"L2\",\n",
    "    \"index_type\":\"IVF_FLAT\",\n",
    "    \"params\" :{\"nlist\":1024}\n",
    "}\n",
    "\n",
    "cache_collection.create_index(\n",
    "    field_name=\"prompt_embedding\",\n",
    "    index_params=index_params\n",
    ")\n",
    "\n",
    "#Flush the collection to persist\n",
    "cache_collection.flush()\n",
    "#Load the collection in memory\n",
    "cache_collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8c8a48",
   "metadata": {},
   "source": [
    "## 04.04. Inference Process with caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27c32ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linkedin/anaconda3/envs/Milvus/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "import os\n",
    "import time\n",
    "\n",
    "#Setup open API key to use OpenAI's LLM\n",
    "openai_api_key=\"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "#Create an LLM object\n",
    "llm= OpenAI(temperature=0., model=\"text-davinci-003\")\n",
    "\n",
    "#Setup embedding model for creating embeddings\n",
    "embeddings_model = OpenAIEmbeddings()\n",
    "\n",
    "#setup threshold for similarity between vectors\n",
    "similarity_threshold=0.3\n",
    "\n",
    "search_params = {\n",
    "    \"metric_type\": \"L2\", \n",
    "    \"offset\": 0, \n",
    "    \"ignore_growing\": False, \n",
    "    \"params\": {\"nprobe\": 20, \"radius\":similarity_threshold}\n",
    "}\n",
    "\n",
    "#create a function to run the inference loop\n",
    "def get_response(prompt):\n",
    "    \n",
    "    start_time=time.time()\n",
    "    #create embedding for incoming prompt\n",
    "    prompt_embed=embeddings_model.embed_query(prompt)\n",
    "    \n",
    "    #Check cache if result exists\n",
    "    cache_results=cache_collection.search(\n",
    "        data=[prompt_embed],\n",
    "        anns_field=\"prompt_embedding\",\n",
    "        param=search_params,\n",
    "        limit=1, #Look for the top result only\n",
    "        expr=None,\n",
    "        output_fields=[\"prompt_text\", \"response_text\"],\n",
    "        consistency_level=\"Strong\"\n",
    "    )\n",
    "        \n",
    "    returned_response =\"None\"\n",
    "    \n",
    "    if ( len(cache_results[0]) > 0 ):\n",
    "        \n",
    "        #Cache hit\n",
    "        print(prompt, \" :\\n Cache hit : \",cache_results[0])\n",
    "        returned_response = cache_results[0][0].entity.get(\"response_text\")\n",
    "    \n",
    "    else:\n",
    "        #Find answer with LLM\n",
    "        llm_response=llm(prompt)\n",
    "        print(prompt, \":\\n LLM returned :\", llm_response)\n",
    "        returned_response = llm_response\n",
    "        \n",
    "        #save prompt/response to cache\n",
    "        prompt_text = [prompt]\n",
    "        prompt_embedding=[prompt_embed]\n",
    "        response_text = [llm_response]\n",
    "\n",
    "        insert_data=[prompt_text, response_text, prompt_embedding]\n",
    "        mr=cache_collection.insert(insert_data)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    print(\"Time elapsed :\",  end_time - start_time, \"\\n\")\n",
    "    return returned_response\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e003faab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In which year was Abraham Lincoln born? :\n",
      " LLM returned : \n",
      "\n",
      "Abraham Lincoln was born in 1809.\n",
      "Time elapsed : 1.182729959487915 \n",
      "\n",
      "What is distance between the sun and the moon? :\n",
      " LLM returned : \n",
      "\n",
      "The average distance between the Sun and the Moon is 238,855 miles (384,400 kilometers).\n",
      "Time elapsed : 1.1267571449279785 \n",
      "\n",
      "How many years have Lebron James played in the NBA? :\n",
      " LLM returned : \n",
      "\n",
      "Lebron James has played in the NBA for 17 years.\n",
      "Time elapsed : 0.8115711212158203 \n",
      "\n",
      "What are the advantages of the python language? :\n",
      " LLM returned : \n",
      "\n",
      "1. Easy to Learn: Python has a very simple and straightforward syntax which makes it very easy to learn and understand. It is also a high-level language, so it abstracts away many of the complex details of the computer.\n",
      "\n",
      "2. Readability: Python code is highly readable and uses English keywords, which makes it easier to understand and debug.\n",
      "\n",
      "3. Versatility: Python can be used for a wide variety of tasks, from web development to data science. It is also highly extensible, so you can add new features and libraries as needed.\n",
      "\n",
      "4. Open Source: Python is an open source language, so it is free to use and modify. This makes it a great choice for anyone who wants to get started with programming.\n",
      "\n",
      "5. Libraries and Frameworks: Python has a large number of libraries and frameworks available, which makes it easy to get started with any project.\n",
      "Time elapsed : 4.27617883682251 \n",
      "\n",
      "What is the typical height of an elephant :\n",
      " LLM returned : \n",
      "\n",
      "The typical height of an elephant is 8 to 13 feet (2.4 to 4 meters).\n",
      "Time elapsed : 1.2326478958129883 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Build up the cache\n",
    "response=get_response(\"In which year was Abraham Lincoln born?\")\n",
    "response=get_response(\"What is distance between the sun and the moon?\")\n",
    "response=get_response(\"How many years have Lebron James played in the NBA?\")\n",
    "response=get_response(\"What are the advantages of the python language?\")\n",
    "response=get_response(\"What is the typical height of an elephant\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7405f61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List some advantages of the python language  :\n",
      " Cache hit :  [\"id: 446817698860241201, distance: 0.04885578155517578, entity: {'response_text': '\\\\n\\\\n1. Easy to Learn: Python has a very simple and straightforward syntax which makes it very easy to learn and understand. It is also a high-level language, so it abstracts away many of the complex details of the computer.\\\\n\\\\n2. Readability: Python code is highly readable and uses English keywords, which makes it easier to understand and debug.\\\\n\\\\n3. Versatility: Python can be used for a wide variety of tasks, from web development to data science. It is also highly extensible, so you can add new features and libraries as needed.\\\\n\\\\n4. Open Source: Python is an open source language, so it is free to use and modify. This makes it a great choice for anyone who wants to get started with programming.\\\\n\\\\n5. Libraries and Frameworks: Python has a large number of libraries and frameworks available, which makes it easy to get started with any project.', 'prompt_text': 'What are the advantages of the python language?'}\"]\n",
      "Time elapsed : 0.6392662525177002 \n",
      "\n",
      "How tall is an elephant?  :\n",
      " Cache hit :  [\"id: 446817698860241203, distance: 0.1144891306757927, entity: {'prompt_text': 'What is the typical height of an elephant', 'response_text': '\\\\n\\\\nThe typical height of an elephant is 8 to 13 feet (2.4 to 4 meters).'}\"]\n",
      "Time elapsed : 0.6020972728729248 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=get_response(\"List some advantages of the python language\")\n",
    "response=get_response(\"How tall is an elephant?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8456c60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
